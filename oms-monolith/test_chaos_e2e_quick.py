#!/usr/bin/env python3
"""
OMS ì¹´ì˜¤ìŠ¤ E2E ì„±ëŠ¥ ê²€ì¦ (Quick Version)
í•µì‹¬ ê·¹í•œ ìƒí™© í…ŒìŠ¤íŠ¸
"""
import asyncio
import json
import sys
import os
from datetime import datetime
import httpx
import nats
import random
import statistics
import time
from typing import Dict, Any, List

sys.path.append('/Users/sihyun/Desktop/ARRAKIS/SPICE/oms-monolith')

from database.simple_terminus_client import SimpleTerminusDBClient

import logging
logging.basicConfig(level=logging.INFO, format='%(asctime)s - %(levelname)s - %(message)s')
logger = logging.getLogger(__name__)


class QuickChaosTest:
    """ë¹ ë¥¸ ì¹´ì˜¤ìŠ¤ í…ŒìŠ¤íŠ¸"""
    
    def __init__(self):
        self.base_url = "http://localhost:8002"
        self.nats_url = "nats://localhost:4222"
        self.results = {
            "burst_test": {},
            "concurrent_chaos": {},
            "event_flood": {},
            "recovery_test": {}
        }
        
    async def setup(self):
        """í™˜ê²½ ì„¤ì •"""
        logger.info("ğŸš€ ì¹´ì˜¤ìŠ¤ E2E ì„±ëŠ¥ í…ŒìŠ¤íŠ¸ ì‹œì‘")
        
        # NATS ì—°ê²°
        self.nc = await nats.connect(self.nats_url)
        
        # DB ì—°ê²°
        self.db = SimpleTerminusDBClient(
            endpoint="http://localhost:6363",
            username="admin",
            password="root",
            database="oms"
        )
        await self.db.connect()
        
        # HTTP í´ë¼ì´ì–¸íŠ¸
        self.http = httpx.AsyncClient(timeout=10.0)
        
    async def test_1_burst_load(self):
        """Test 1: ìˆœê°„ í­ë°œì  ë¶€í•˜"""
        logger.info("\n" + "="*60)
        logger.info("ğŸ’¥ Test 1: ìˆœê°„ í­ë°œì  ë¶€í•˜ (200 ë™ì‹œ ìš”ì²­)")
        logger.info("="*60)
        
        results = {
            "total": 200,
            "success": 0,
            "failed": 0,
            "latencies": []
        }
        
        async def burst_request(i):
            start = time.time()
            try:
                if i % 3 == 0:  # CREATE
                    resp = await self.http.post(
                        f"{self.base_url}/api/v1/schemas/main/object-types",
                        json={
                            "name": f"Burst_{i}_{random.randint(1000,9999)}",
                            "displayName": f"í­ë°œ {i}",
                            "description": "Burst test"
                        },
                        headers={"Authorization": f"Bearer burst-{i}"}
                    )
                elif i % 3 == 1:  # READ
                    resp = await self.http.get(
                        f"{self.base_url}/api/v1/schemas/main/object-types",
                        headers={"Authorization": f"Bearer burst-{i}"}
                    )
                else:  # HEALTH CHECK
                    resp = await self.http.get(f"{self.base_url}/health")
                    
                latency = (time.time() - start) * 1000
                
                if resp.status_code in [200, 201]:
                    return True, latency
                else:
                    return False, latency
                    
            except Exception as e:
                latency = (time.time() - start) * 1000
                return False, latency
                
        # 200ê°œ ë™ì‹œ ì‹¤í–‰
        start_time = time.time()
        tasks = [burst_request(i) for i in range(200)]
        burst_results = await asyncio.gather(*tasks)
        total_time = time.time() - start_time
        
        for success, latency in burst_results:
            if success:
                results["success"] += 1
            else:
                results["failed"] += 1
            results["latencies"].append(latency)
            
        # í†µê³„
        avg_latency = statistics.mean(results["latencies"])
        p95_latency = statistics.quantiles(results["latencies"], n=20)[18]
        
        logger.info(f"\nğŸ“Š ê²°ê³¼:")
        logger.info(f"   ì„±ê³µ: {results['success']}/{results['total']} ({results['success']/results['total']*100:.1f}%)")
        logger.info(f"   í‰ê·  ì§€ì—°: {avg_latency:.2f}ms")
        logger.info(f"   P95 ì§€ì—°: {p95_latency:.2f}ms")
        logger.info(f"   ì²˜ë¦¬ ì†ë„: {results['total']/total_time:.2f} req/sec")
        
        self.results["burst_test"] = results
        return results
        
    async def test_2_concurrent_chaos(self):
        """Test 2: ë™ì‹œ ë‹¤ë°œì  ì¹´ì˜¤ìŠ¤"""
        logger.info("\n" + "="*60)
        logger.info("ğŸŒªï¸ Test 2: ë™ì‹œ ë‹¤ë°œì  ì¹´ì˜¤ìŠ¤")
        logger.info("="*60)
        
        results = {
            "concurrent_updates": 0,
            "race_conditions": 0,
            "conflicts_handled": 0
        }
        
        # ë™ì¼ ê°ì²´ì— ëŒ€í•œ 50ê°œ ë™ì‹œ ìˆ˜ì •
        test_object_id = f"ChaosTest_{random.randint(1000,9999)}"
        
        # ë¨¼ì € ê°ì²´ ìƒì„±
        create_resp = await self.http.post(
            f"{self.base_url}/api/v1/schemas/main/object-types",
            json={
                "name": test_object_id,
                "displayName": "ì¹´ì˜¤ìŠ¤ í…ŒìŠ¤íŠ¸ ê°ì²´",
                "description": "ë™ì‹œ ìˆ˜ì • í…ŒìŠ¤íŠ¸"
            },
            headers={"Authorization": "Bearer chaos-creator"}
        )
        
        if create_resp.status_code == 200:
            obj_data = create_resp.json()
            obj_id = obj_data.get('id', test_object_id)
            
            logger.info(f"\nğŸ¯ {obj_id}ì— 50ê°œ ë™ì‹œ ìˆ˜ì • ì‹œë„...")
            
            async def concurrent_update(i):
                try:
                    resp = await self.http.put(
                        f"{self.base_url}/api/v1/schemas/main/object-types/{obj_id}",
                        json={"description": f"ë™ì‹œ ìˆ˜ì • #{i} at {datetime.now().isoformat()}"},
                        headers={"Authorization": f"Bearer user-{i}"}
                    )
                    return resp.status_code == 200
                except:
                    return False
                    
            tasks = [concurrent_update(i) for i in range(50)]
            update_results = await asyncio.gather(*tasks)
            
            results["concurrent_updates"] = sum(1 for r in update_results if r)
            results["race_conditions"] = 50 - results["concurrent_updates"]
            
        # ì´ë²¤íŠ¸ + API + DB ë™ì‹œ ì‘ì—…
        logger.info("\nğŸ¯ ì´ë²¤íŠ¸ + API + DB ë™ì‹œ ì‘ì—…...")
        
        async def multi_chaos():
            tasks = []
            
            # 10ê°œ ì´ë²¤íŠ¸ ë°œí–‰
            for i in range(10):
                event = self.nc.publish(
                    f"oms.chaos.test",
                    json.dumps({"id": f"chaos-{i}", "time": datetime.now().isoformat()}).encode()
                )
                tasks.append(event)
                
            # 10ê°œ API í˜¸ì¶œ
            for i in range(10):
                api_call = self.http.get(
                    f"{self.base_url}/api/v1/schemas/main/object-types",
                    headers={"Authorization": f"Bearer chaos-{i}"}
                )
                tasks.append(api_call)
                
            # 10ê°œ DB ì§ì ‘ ì¡°íšŒ
            for i in range(10):
                db_query = self.db.client.get(
                    "http://localhost:6363/api/document/admin/oms?type=ObjectType&limit=1",
                    auth=("admin", "root")
                )
                tasks.append(db_query)
                
            results_multi = await asyncio.gather(*tasks, return_exceptions=True)
            
            success_count = sum(1 for r in results_multi if not isinstance(r, Exception))
            results["conflicts_handled"] = success_count
            
        await multi_chaos()
        
        logger.info(f"\nğŸ“Š ê²°ê³¼:")
        logger.info(f"   ë™ì‹œ ìˆ˜ì • ì„±ê³µ: {results['concurrent_updates']}/50")
        logger.info(f"   ê²½ìŸ ìƒíƒœ ë°œìƒ: {results['race_conditions']}")
        logger.info(f"   ë™ì‹œ ì‘ì—… ì²˜ë¦¬: {results['conflicts_handled']}/30")
        
        self.results["concurrent_chaos"] = results
        return results
        
    async def test_3_event_flood(self):
        """Test 3: ì´ë²¤íŠ¸ í™ìˆ˜"""
        logger.info("\n" + "="*60)
        logger.info("ğŸŒŠ Test 3: ì´ë²¤íŠ¸ í™ìˆ˜ (1000 ì´ë²¤íŠ¸/ì´ˆ)")
        logger.info("="*60)
        
        results = {
            "events_sent": 0,
            "duration": 0,
            "events_per_second": 0
        }
        
        # 1000ê°œ ì´ë²¤íŠ¸ë¥¼ ìµœëŒ€í•œ ë¹ ë¥´ê²Œ ë°œí–‰
        start_time = time.time()
        
        for i in range(1000):
            event = {
                "specversion": "1.0",
                "type": "com.oms.flood.test",
                "source": "/oms/chaos",
                "id": f"flood-{i}",
                "time": datetime.now().isoformat(),
                "data": {"index": i, "random": random.random()}
            }
            
            try:
                await self.nc.publish(
                    f"oms.flood.{i%10}",
                    json.dumps(event).encode()
                )
                results["events_sent"] += 1
            except:
                pass
                
            # 10ê°œë§ˆë‹¤ ì•„ì£¼ ì§§ì€ ëŒ€ê¸°
            if i % 10 == 0:
                await asyncio.sleep(0.001)
                
        results["duration"] = time.time() - start_time
        results["events_per_second"] = results["events_sent"] / results["duration"]
        
        logger.info(f"\nğŸ“Š ê²°ê³¼:")
        logger.info(f"   ë°œí–‰ëœ ì´ë²¤íŠ¸: {results['events_sent']}")
        logger.info(f"   ì†Œìš” ì‹œê°„: {results['duration']:.2f}ì´ˆ")
        logger.info(f"   ì²˜ë¦¬ ì†ë„: {results['events_per_second']:.2f} events/sec")
        
        self.results["event_flood"] = results
        return results
        
    async def test_4_recovery(self):
        """Test 4: ì¥ì•  ë³µêµ¬ í…ŒìŠ¤íŠ¸"""
        logger.info("\n" + "="*60)
        logger.info("ğŸ”§ Test 4: ì¥ì•  ë³µêµ¬ ëŠ¥ë ¥")
        logger.info("="*60)
        
        results = {
            "baseline_latency": 0,
            "stressed_latency": 0,
            "recovery_time": 0,
            "recovered": False
        }
        
        # 1. ê¸°ì¤€ì„  ì¸¡ì •
        logger.info("\nğŸ“ ê¸°ì¤€ì„  ì¸¡ì •...")
        baseline_latencies = []
        
        for i in range(5):
            start = time.time()
            resp = await self.http.get(f"{self.base_url}/health")
            latency = (time.time() - start) * 1000
            baseline_latencies.append(latency)
            await asyncio.sleep(0.1)
            
        results["baseline_latency"] = statistics.mean(baseline_latencies)
        logger.info(f"   ê¸°ì¤€ ì‘ë‹µì‹œê°„: {results['baseline_latency']:.2f}ms")
        
        # 2. ìŠ¤íŠ¸ë ˆìŠ¤ ë¶€í•˜
        logger.info("\nğŸ’¥ ê·¹ì‹¬í•œ ë¶€í•˜ ê°€ì¤‘...")
        
        async def stress_load():
            tasks = []
            for i in range(100):
                task = self.http.post(
                    f"{self.base_url}/api/v1/schemas/main/object-types",
                    json={
                        "name": f"Stress_{i}_{random.randint(1000,9999)}",
                        "displayName": f"ìŠ¤íŠ¸ë ˆìŠ¤ {i}",
                        "description": "x" * 1000
                    },
                    headers={"Authorization": f"Bearer stress-{i}"},
                    timeout=2.0
                )
                tasks.append(task)
                
            await asyncio.gather(*tasks, return_exceptions=True)
            
        await stress_load()
        
        # ìŠ¤íŠ¸ë ˆìŠ¤ ìƒíƒœ ì¸¡ì •
        stressed_latencies = []
        for i in range(3):
            start = time.time()
            try:
                resp = await self.http.get(f"{self.base_url}/health", timeout=2.0)
                latency = (time.time() - start) * 1000
                stressed_latencies.append(latency)
            except:
                stressed_latencies.append(2000)  # timeout
                
        results["stressed_latency"] = statistics.mean(stressed_latencies)
        logger.info(f"   ìŠ¤íŠ¸ë ˆìŠ¤ ì‘ë‹µì‹œê°„: {results['stressed_latency']:.2f}ms")
        
        # 3. ë³µêµ¬ ì‹œê°„ ì¸¡ì •
        logger.info("\nâ±ï¸ ë³µêµ¬ ì‹œê°„ ì¸¡ì •...")
        recovery_start = time.time()
        
        while (time.time() - recovery_start) < 10:  # ìµœëŒ€ 10ì´ˆ
            try:
                start = time.time()
                resp = await self.http.get(f"{self.base_url}/health", timeout=1.0)
                latency = (time.time() - start) * 1000
                
                # ê¸°ì¤€ì„ ì˜ 2ë°° ì´ë‚´ë¡œ ëŒì•„ì˜¤ë©´ ë³µêµ¬
                if latency < results["baseline_latency"] * 2:
                    results["recovery_time"] = time.time() - recovery_start
                    results["recovered"] = True
                    break
                    
            except:
                pass
                
            await asyncio.sleep(0.5)
            
        logger.info(f"\nğŸ“Š ê²°ê³¼:")
        logger.info(f"   ê¸°ì¤€ ì‘ë‹µì‹œê°„: {results['baseline_latency']:.2f}ms")
        logger.info(f"   ìŠ¤íŠ¸ë ˆìŠ¤ ì‘ë‹µì‹œê°„: {results['stressed_latency']:.2f}ms")
        logger.info(f"   ë³µêµ¬ ì‹œê°„: {results['recovery_time']:.2f}ì´ˆ")
        logger.info(f"   ë³µêµ¬ ìƒíƒœ: {'âœ… ì„±ê³µ' if results['recovered'] else 'âŒ ì‹¤íŒ¨'}")
        
        self.results["recovery_test"] = results
        return results
        
    async def generate_report(self):
        """ìµœì¢… ë³´ê³ ì„œ"""
        logger.info("\n" + "="*60)
        logger.info("ğŸ“Š ì¹´ì˜¤ìŠ¤ E2E ì„±ëŠ¥ í…ŒìŠ¤íŠ¸ ê²°ê³¼")
        logger.info("="*60)
        
        # 1. ìˆœê°„ ë¶€í•˜ ì²˜ë¦¬
        burst = self.results["burst_test"]
        burst_score = 1 if burst.get("success", 0) > 160 else 0  # 80% ì´ìƒ
        
        logger.info("\n### 1. ìˆœê°„ ë¶€í•˜ ì²˜ë¦¬ ëŠ¥ë ¥")
        logger.info(f"âœ… ì„±ê³µë¥ : {burst.get('success', 0)/200*100:.1f}%")
        logger.info(f"â±ï¸ í‰ê·  ì§€ì—°: {statistics.mean(burst.get('latencies', [0])):.2f}ms")
        logger.info(f"ì ìˆ˜: {'âœ…' if burst_score else 'âŒ'}")
        
        # 2. ë™ì‹œì„± ì²˜ë¦¬
        chaos = self.results["concurrent_chaos"]
        chaos_score = 1 if chaos.get("concurrent_updates", 0) > 0 else 0
        
        logger.info("\n### 2. ë™ì‹œì„± ë° ê²½ìŸ ìƒíƒœ ì²˜ë¦¬")
        logger.info(f"âœ… ë™ì‹œ ìˆ˜ì • ì²˜ë¦¬: {chaos.get('concurrent_updates', 0)}/50")
        logger.info(f"âœ… ë©€í‹° ì‘ì—… ì²˜ë¦¬: {chaos.get('conflicts_handled', 0)}/30")
        logger.info(f"ì ìˆ˜: {'âœ…' if chaos_score else 'âŒ'}")
        
        # 3. ì´ë²¤íŠ¸ ì²˜ë¦¬
        flood = self.results["event_flood"]
        flood_score = 1 if flood.get("events_per_second", 0) > 500 else 0
        
        logger.info("\n### 3. ì´ë²¤íŠ¸ ì²˜ë¦¬ ì„±ëŠ¥")
        logger.info(f"âœ… ì²˜ë¦¬ ì†ë„: {flood.get('events_per_second', 0):.2f} events/sec")
        logger.info(f"ì ìˆ˜: {'âœ…' if flood_score else 'âŒ'}")
        
        # 4. ë³µêµ¬ ëŠ¥ë ¥
        recovery = self.results["recovery_test"]
        recovery_score = 1 if recovery.get("recovered", False) else 0
        
        logger.info("\n### 4. ì¥ì•  ë³µêµ¬ ëŠ¥ë ¥")
        logger.info(f"âœ… ë³µêµ¬ ì‹œê°„: {recovery.get('recovery_time', 0):.2f}ì´ˆ")
        logger.info(f"âœ… ë³µêµ¬ ìƒíƒœ: {'ì„±ê³µ' if recovery.get('recovered', False) else 'ì‹¤íŒ¨'}")
        logger.info(f"ì ìˆ˜: {'âœ…' if recovery_score else 'âŒ'}")
        
        # ì´ì 
        total_score = burst_score + chaos_score + flood_score + recovery_score
        
        logger.info("\n" + "="*60)
        logger.info(f"ğŸ† ìµœì¢… ì ìˆ˜: {total_score}/4 ({total_score/4*100:.0f}%)")
        logger.info("="*60)
        
        if total_score >= 3:
            logger.info("\nâœ… í”„ë¡œë•ì…˜ ì¤€ë¹„ ì™„ë£Œ")
            logger.info("   - ìˆœê°„ ë¶€í•˜ ì²˜ë¦¬ ê°€ëŠ¥")
            logger.info("   - ë™ì‹œì„± ë¬¸ì œ ì²˜ë¦¬")
            logger.info("   - ë†’ì€ ì´ë²¤íŠ¸ ì²˜ë¦¬ëŸ‰")
            logger.info("   - ë¹ ë¥¸ ë³µêµ¬ ëŠ¥ë ¥")
        else:
            logger.info("\nâš ï¸ ê°œì„  í•„ìš” ì‚¬í•­:")
            if not burst_score:
                logger.info("   - API ì‘ë‹µ ì†ë„ ìµœì í™”")
            if not chaos_score:
                logger.info("   - ë™ì‹œì„± ì œì–´ ê°•í™”")
            if not flood_score:
                logger.info("   - ì´ë²¤íŠ¸ ì²˜ë¦¬ ì„±ëŠ¥ ê°œì„ ")
            if not recovery_score:
                logger.info("   - ì¥ì•  ë³µêµ¬ ë©”ì»¤ë‹ˆì¦˜ ê°•í™”")
                
        # ê¶Œì¥ì‚¬í•­
        logger.info("\nğŸ’¡ ê¶Œì¥ ì‚¬í•­:")
        logger.info("1. ì—°ê²° í’€ë§ ìµœì í™”")
        logger.info("2. ìºì‹± ì „ëµ ë„ì…")
        logger.info("3. ë¹„ë™ê¸° ì²˜ë¦¬ ê°•í™”")
        logger.info("4. ë¡œë“œ ë°¸ëŸ°ì‹± ê³ ë ¤")
        
    async def cleanup(self):
        """ì •ë¦¬"""
        await self.nc.close()
        await self.http.aclose()
        await self.db.disconnect()
        
    async def run(self):
        """ì „ì²´ ì‹¤í–‰"""
        await self.setup()
        
        await self.test_1_burst_load()
        await asyncio.sleep(1)
        
        await self.test_2_concurrent_chaos()
        await asyncio.sleep(1)
        
        await self.test_3_event_flood()
        await asyncio.sleep(1)
        
        await self.test_4_recovery()
        
        await self.generate_report()
        
        await self.cleanup()


async def main():
    test = QuickChaosTest()
    await test.run()


if __name__ == "__main__":
    logger.info("ğŸš€ OMS ì¹´ì˜¤ìŠ¤ E2E ì„±ëŠ¥ ê²€ì¦ (Quick Version)")
    asyncio.run(main())